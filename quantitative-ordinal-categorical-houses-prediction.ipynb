{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yamarieli/quantitative-ordinal-categorical-houses-prediction?scriptVersionId=123851512\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## The goal is to answer the following questions\n<div>\n    <span><b>Get familiar with the data</b></span>\n    <ul>\n        <li>What the type of each column?\n        <ol>\n            <li>quantitative</li>\n            <li>ordinal</li>\n            <li>categorical</li>\n            </ol>\n        </li>\n        <li>What the meaning of each column?</li>\n        <li>What are the values of each column?</li>\n    </ul>\n</div>\n\n<div>\n    <span><b>Clean the data</b></span>\n    <ul>\n        <li>What are the outlairs?</li>\n        <li>how much should we clean?</li>\n    </ul>\n</div>\n\n<div>\n    <span><b>Prediction</b></span>\n    <ul>\n        <li>What is the best method for each type?</li>\n        <li>How to apply the insights to the data?</li>\n    </ul>\n</div>","metadata":{}},{"cell_type":"markdown","source":"### Note:\n**`In this notebook there are 3D animations, it is recommended to go down to seeðŸ˜ƒðŸ‘Œ`**","metadata":{}},{"cell_type":"code","source":"from math import ceil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport os\nfrom typing import Tuple, Union, List\nimport imageio\nfrom IPython.display import Image\nfrom scipy.stats import spearmanr\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-10T09:31:33.54052Z","iopub.execute_input":"2023-02-10T09:31:33.541422Z","iopub.status.idle":"2023-02-10T09:31:34.607Z","shell.execute_reply.started":"2023-02-10T09:31:33.541322Z","shell.execute_reply":"2023-02-10T09:31:34.605152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\ndf = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-02-10T09:32:22.675572Z","iopub.execute_input":"2023-02-10T09:32:22.675932Z","iopub.status.idle":"2023-02-10T09:32:22.766782Z","shell.execute_reply.started":"2023-02-10T09:32:22.675902Z","shell.execute_reply":"2023-02-10T09:32:22.765792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_xy = pd.read_excel('/kaggle/input/nei-xy-full/nei_full.xlsx')\ndf_xy.rename(columns={'short': 'Neighborhood'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T09:48:06.806565Z","iopub.execute_input":"2023-02-10T09:48:06.807293Z","iopub.status.idle":"2023-02-10T09:48:06.829683Z","shell.execute_reply.started":"2023-02-10T09:48:06.807256Z","shell.execute_reply":"2023-02-10T09:48:06.828767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_xy = df_xy.merge(right=df[['Neighborhood', 'SalePrice']], on='Neighborhood')","metadata":{"execution":{"iopub.status.busy":"2023-02-10T09:48:09.853697Z","iopub.execute_input":"2023-02-10T09:48:09.854902Z","iopub.status.idle":"2023-02-10T09:48:09.865854Z","shell.execute_reply.started":"2023-02-10T09:48:09.854861Z","shell.execute_reply":"2023-02-10T09:48:09.864604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport folium\nfrom folium.plugins import HeatMap\nfrom IPython.display import IFrame","metadata":{"execution":{"iopub.status.busy":"2023-02-10T09:51:43.66591Z","iopub.execute_input":"2023-02-10T09:51:43.666513Z","iopub.status.idle":"2023-02-10T09:51:44.203486Z","shell.execute_reply.started":"2023-02-10T09:51:43.666468Z","shell.execute_reply":"2023-02-10T09:51:44.202568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name = 'nei_heat.html'\ntiles = 'openstreetmap' # 'cartodbpositron' is also available\nlocation=[df_xy.Latitude.mean(), df_xy.Longitude.mean()]\n\nthis_map = folium.Map(location=location, tiles=tiles, zoom_start=12)\nHeatMap(data=df_xy[['Latitude', 'Longitude']], radius=15).add_to(this_map)\nthis_map.save(file_name)\n\nframe = IFrame(file_name, width='70%', height='500px')\nframe","metadata":{"execution":{"iopub.status.busy":"2023-02-10T09:55:25.664177Z","iopub.execute_input":"2023-02-10T09:55:25.664528Z","iopub.status.idle":"2023-02-10T09:55:25.698613Z","shell.execute_reply.started":"2023-02-10T09:55:25.664498Z","shell.execute_reply":"2023-02-10T09:55:25.697713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's get familiar with the data","metadata":{"execution":{"iopub.status.busy":"2022-12-24T16:31:41.030379Z","iopub.execute_input":"2022-12-24T16:31:41.030791Z","iopub.status.idle":"2022-12-24T16:31:41.035575Z","shell.execute_reply.started":"2022-12-24T16:31:41.030756Z","shell.execute_reply":"2022-12-24T16:31:41.034453Z"}}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-02-07T20:15:48.511439Z","iopub.execute_input":"2023-02-07T20:15:48.511826Z","iopub.status.idle":"2023-02-07T20:15:48.519502Z","shell.execute_reply.started":"2023-02-07T20:15:48.511794Z","shell.execute_reply":"2023-02-07T20:15:48.518434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### wow! this is a lot...\n### Let's understand the names meaning by 'data_description.txt' file\n*(uncomment to see description)*","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt', 'r') as f:\n    print(f.read())","metadata":{"execution":{"iopub.status.busy":"2023-02-07T20:15:53.620595Z","iopub.execute_input":"2023-02-07T20:15:53.621168Z","iopub.status.idle":"2023-02-07T20:15:53.634768Z","shell.execute_reply.started":"2023-02-07T20:15:53.621116Z","shell.execute_reply":"2023-02-07T20:15:53.633718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's split by 3 types:\n* quantitative\n* ordinal\n* categorical\n\n## Continuous data:","metadata":{}},{"cell_type":"code","source":"continuous_columns = {'GarageArea', 'SalePrice', 'GrLivArea', 'LowQualFinSF', '2ndFlrSF', '1stFlrSF', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF2', 'BsmtFinSF1', 'LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea'}\ndf_continuous = df[[*continuous_columns]]","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:40:56.287197Z","iopub.execute_input":"2023-02-07T19:40:56.287573Z","iopub.status.idle":"2023-02-07T19:40:56.297098Z","shell.execute_reply.started":"2023-02-07T19:40:56.287542Z","shell.execute_reply":"2023-02-07T19:40:56.296062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Take a first look at the columns","metadata":{}},{"cell_type":"code","source":"continuous_columns.remove('SalePrice')\nGRAPH_COUNT = len(continuous_columns)\nGRAPH_IN_A_ROW = 2\n\nfig, axs = plt.subplots(int(GRAPH_COUNT/GRAPH_IN_A_ROW), GRAPH_IN_A_ROW, figsize = (20, 25))\n\nfor col, ax in zip(continuous_columns, axs.flat):\n    ax.set_title(col)\n    ax.scatter(df_continuous[col].tolist(), df_continuous['SalePrice'].tolist())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:40:56.97337Z","iopub.execute_input":"2023-02-07T19:40:56.974076Z","iopub.status.idle":"2023-02-07T19:40:58.707054Z","shell.execute_reply.started":"2023-02-07T19:40:56.974029Z","shell.execute_reply":"2023-02-07T19:40:58.706035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It's seems that the main correlation is with ['GrLivArea', '1stFlrSF', 'LotArea']\nlet's see it in a heatmap","metadata":{}},{"cell_type":"code","source":"corr = df_continuous.corr()\nfig, ax = plt.subplots(figsize = (20, 15))\nsns.heatmap(corr, annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:40:58.70854Z","iopub.execute_input":"2023-02-07T19:40:58.708881Z","iopub.status.idle":"2023-02-07T19:41:00.112601Z","shell.execute_reply.started":"2023-02-07T19:40:58.708852Z","shell.execute_reply":"2023-02-07T19:41:00.111695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It's seems that in the heat table you can see things differently\nmost of the columns that correlated with **SalePrice** are correlated with each other, so they wouldn't contribute to the prediction.<br>\nPrediction by too much variables may be problematic:\n<ul>\n    <li>Each variable contributes a little noise. Many small noises add up to a big noise.</li>\n    <li>Clearing a few outlairs from many variables may sum up to clearing many values and losing a large part of the learning data</li>\n<ul>","metadata":{}},{"cell_type":"markdown","source":"So we should choose the best one and remove the rest, it will be **GrLivArea**.\n\nNote that **YearBuilt** also in good correlation **SalePrice**, but unlike most of the other columns, it has a relatively low correlation with **GrLivArea**.<br>\nTherefore it might help.","metadata":{}},{"cell_type":"code","source":"cols = ['GrLivArea', 'YearBuilt']\ndf_continuous = df[['SalePrice', 'Neighborhood', *cols]].copy()\n\nCOLS_COUNT = len(cols)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:00.939113Z","iopub.execute_input":"2023-02-07T19:41:00.939483Z","iopub.status.idle":"2023-02-07T19:41:00.947646Z","shell.execute_reply.started":"2023-02-07T19:41:00.939454Z","shell.execute_reply":"2023-02-07T19:41:00.94656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ML already?? not yet -> cleaning time","metadata":{}},{"cell_type":"markdown","source":"<h2>Is <b>3M$</b> is a lot?</h2>\n    <h5>well, It depends...</h5>\n<p>\n    <span>\n    The real question is whether <b>this price</b> represents a reasonable value for <b>this property</b>.<br>\n    We will refer to:\n    </span>\n    <ul>\n        <li>The <b>neighborhood</b> where the property is</li>\n        <li>The main <b>continuous values</b></li>\n    </ul>\n    <span>Therefore I will:</span>\n    <ol>\n        <li>Calculate the ratio between the <b>price</b> and the <b>continuous values</b>  for each <b>neighborhood</b></li>\n        <li>Remove the outlairs</li>\n    </ol>\n</p>","metadata":{}},{"cell_type":"code","source":"def get_ratio(df: pd.DataFrame, col_name: str) -> Tuple[pd.DataFrame, str]:\n    new_col_name = f'{col_name}_ratio'\n    df[new_col_name] = df.apply(lambda row: row[col_name]/row['SalePrice'], axis=1).copy()\n    return df, new_col_name","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:02.542809Z","iopub.execute_input":"2023-02-07T19:41:02.543221Z","iopub.status.idle":"2023-02-07T19:41:02.549965Z","shell.execute_reply.started":"2023-02-07T19:41:02.543187Z","shell.execute_reply":"2023-02-07T19:41:02.548788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_quantile_by_group(df: pd.DataFrame, groupby_column: str, quan_columns: List[str] , q_size=0.01) -> pd.DataFrame:\n    grouped = df.groupby(groupby_column)\n    \n    # Compute the lower quantile for each group\n    low_q_df = grouped[quan_columns].quantile(q_size)\n    # Fix the the names of the columns\n    low_q_df.rename(columns={col: f'{col}_low_quantile' for col in low_q_df.columns}, inplace=True)\n    \n    # Compute the higher quantile for each group\n    high_q_df = grouped[quan_columns].quantile(1-q_size)\n    # Fix the the names of the columns\n    high_q_df.rename(columns={col: f'{col}_high_quantile' for col in high_q_df.columns}, inplace=True)\n\n    return pd.merge(low_q_df, high_q_df, left_index=True, right_index=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:03.151704Z","iopub.execute_input":"2023-02-07T19:41:03.153984Z","iopub.status.idle":"2023-02-07T19:41:03.162378Z","shell.execute_reply.started":"2023-02-07T19:41:03.153929Z","shell.execute_reply":"2023-02-07T19:41:03.161206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratio_cols = []\nfor col in cols:\n    df_continuous, ratio_col = get_ratio(df_continuous, col)\n    ratio_cols.append(ratio_col)\n\nprint('ratio_cols = ', ratio_cols)\ndf_continuous.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:05.417476Z","iopub.execute_input":"2023-02-07T19:41:05.418426Z","iopub.status.idle":"2023-02-07T19:41:05.474053Z","shell.execute_reply.started":"2023-02-07T19:41:05.418388Z","shell.execute_reply":"2023-02-07T19:41:05.47309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Dataframe of high and low quantile of the columns we choose for each Neighborhood\n\ndf_Neighborhood_ratio_quantile = get_quantile_by_group(df_continuous, 'Neighborhood', ratio_cols)\ndf_Neighborhood_ratio_quantile.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:05.873337Z","iopub.execute_input":"2023-02-07T19:41:05.874028Z","iopub.status.idle":"2023-02-07T19:41:05.903941Z","shell.execute_reply.started":"2023-02-07T19:41:05.873992Z","shell.execute_reply":"2023-02-07T19:41:05.902812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add the quantile columns to the df_continuous\n\ndf_continuous = pd.merge(left=df_continuous, right=df_Neighborhood_ratio_quantile,\n         left_on='Neighborhood', right_index=True)\ndf_continuous.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:06.376722Z","iopub.execute_input":"2023-02-07T19:41:06.379382Z","iopub.status.idle":"2023-02-07T19:41:06.399758Z","shell.execute_reply.started":"2023-02-07T19:41:06.379345Z","shell.execute_reply":"2023-02-07T19:41:06.398703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove outlairs\n\nfor rc in ratio_cols:\n    if df_continuous[rc].shape[0] > 4:\n        df_continuous = df_continuous[\n            (df_continuous[rc] >= df_continuous[f'{rc}_low_quantile']) &\n            (df_continuous[rc] <= df_continuous[f'{rc}_high_quantile'])\n        ]","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:07.162163Z","iopub.execute_input":"2023-02-07T19:41:07.16253Z","iopub.status.idle":"2023-02-07T19:41:07.171837Z","shell.execute_reply.started":"2023-02-07T19:41:07.162498Z","shell.execute_reply":"2023-02-07T19:41:07.170789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (18,5)\n\nfor col in cols:\n    plt.title(col)\n    plt.scatter(df_continuous[col].tolist(), df_continuous['SalePrice'].tolist())\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:08.644802Z","iopub.execute_input":"2023-02-07T19:41:08.645161Z","iopub.status.idle":"2023-02-07T19:41:09.072427Z","shell.execute_reply.started":"2023-02-07T19:41:08.64513Z","shell.execute_reply":"2023-02-07T19:41:09.07154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xdata, ydata, zdata = df_continuous['GrLivArea'], df_continuous['YearBuilt'], df_continuous['SalePrice']\n\nhorizontal_range = list(range(10, 70, 2))\nvertical_range = horizontal_range\n\nfig = plt.figure(figsize=(20,20))\nax = fig.add_subplot(211,projection='3d')\nax.scatter3D(xdata, ydata, zdata, c=zdata,  \n                cmap='viridis', edgecolor='none');\n\nax.set_xlabel('GrLivArea')\nax.set_ylabel('YearBuilt')\nax.set_zlabel('SalePrice');\n\nfor i in horizontal_range:\n    ax.view_init(i, i)\n    plt.savefig(f'{i}.png')\n    \nplt.clf()\n\nwith imageio.get_writer('area_year_price.gif', mode='I', duration=0.15) as writer:\n    for i in horizontal_range:\n        file_name = f'{i}.png'\n        image = imageio.imread(file_name)\n        os.remove(file_name)\n        writer.append_data(image)\n\nwith open('area_year_price.gif','rb') as f:\n    display(Image(data=f.read(), format='png'))","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:09.109061Z","iopub.execute_input":"2023-02-07T19:41:09.109339Z","iopub.status.idle":"2023-02-07T19:41:23.849079Z","shell.execute_reply.started":"2023-02-07T19:41:09.109314Z","shell.execute_reply":"2023-02-07T19:41:23.848253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>\nLooking much better!<br>\nNow it's time for reggresion\n</h2>","metadata":{}},{"cell_type":"code","source":"df_continuous.groupby('Neighborhood')['Neighborhood'].count()","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:34.565697Z","iopub.execute_input":"2023-02-07T19:41:34.566363Z","iopub.status.idle":"2023-02-07T19:41:34.576658Z","shell.execute_reply.started":"2023-02-07T19:41:34.566327Z","shell.execute_reply":"2023-02-07T19:41:34.575656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's seems that some neighborhoods don't have a lot of data, so I will use all the data to train, and test a set of values in the range.","metadata":{}},{"cell_type":"code","source":"def get_N_numbers_in_range(N: int, low: float, high: float):\n    d = (high-low) / N\n    return list(map(lambda x: (x*d)+(low-d), range(1, N+1)))","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:35.579053Z","iopub.execute_input":"2023-02-07T19:41:35.579852Z","iopub.status.idle":"2023-02-07T19:41:35.586387Z","shell.execute_reply.started":"2023-02-07T19:41:35.579762Z","shell.execute_reply":"2023-02-07T19:41:35.585305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compute the regressor of each neighborhood\n* The reggresor will be saved in the `dict` **area_year_regressors**\n* The data for the plot will be saved in the `list` **fig_data**","metadata":{}},{"cell_type":"code","source":"# this dict keys will be the neighborhoods names and the values will be the corresponding models\narea_year_regressors = {}\nfig_data = []\n\nfor nei in df_continuous.Neighborhood.unique():\n    # only rows of this Neighborhood\n    df_temp = df_continuous[df_continuous.Neighborhood == nei]\n    X_train, y_train = df_temp[cols].to_numpy(), df_temp.SalePrice.to_numpy()\n    \n    poly = PolynomialFeatures(2)\n    regressor = Ridge(alpha=1000)\n    \n    X_train_trans = poly.fit_transform(X_train)\n    regressor.fit(X_train_trans, y_train)\n    \n    # add the new calculated regressor to the regressors dict\n    area_year_regressors[nei] = regressor\n\n    GLA_range = get_N_numbers_in_range(10, df_temp.GrLivArea.min(), df_temp.GrLivArea.max())\n    YB_range = get_N_numbers_in_range(10, df_temp.YearBuilt.min(), df_temp.YearBuilt.max())\n    \n    X_test = np.array([[g, y] for g in GLA_range for y in YB_range])\n    X_test_trans = poly.fit_transform(X_test)\n    y_predict = regressor.predict(X_test_trans)\n\n    xdata, ydata, zdata = df_temp['GrLivArea'], df_temp['YearBuilt'], df_temp['SalePrice']\n    xtest, ytest, ztest = X_test[:,0], X_test[:,1], y_predict\n    \n    ax_data = {\n        'nei': nei,\n        'org_data': (xdata, ydata, zdata),\n        'test': (xtest, ytest, ztest)\n    }\n    \n    fig_data.append(ax_data)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:39.780818Z","iopub.execute_input":"2023-02-07T19:41:39.781184Z","iopub.status.idle":"2023-02-07T19:41:39.856809Z","shell.execute_reply.started":"2023-02-07T19:41:39.781154Z","shell.execute_reply":"2023-02-07T19:41:39.855853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### For each angle I will create one big plot for all the subplots \nSave it as diffrent image","metadata":{}},{"cell_type":"code","source":"single_sub_size = 10\nncols = 2\nnrows = ceil(df_continuous.Neighborhood.unique().size/ncols)\n\nfig = plt.figure(figsize=(single_sub_size*ncols, single_sub_size*nrows))\nangles = list(range(10, 70, 2))\n\nfor angle in angles:\n    for index, ax_data in enumerate(fig_data, start=1):    \n        # create the fig object\n        ax = fig.add_subplot(nrows, ncols, index, projection='3d')\n\n        nei = ax_data['nei']\n        org_data = ax_data['org_data']\n        test = ax_data['test']\n\n        ax.scatter3D(*org_data, c=org_data[2], cmap='viridis', edgecolor='none');\n        ax.scatter3D(*test, c=test[2], cmap='Greens', edgecolor='none')\n\n        ax.set_xlabel('GrLivArea')\n        ax.set_ylabel('YearBuilt')\n        ax.set_zlabel('SalePrice')\n        ax.set_title(nei)\n        ax.view_init(angle, angle)\n    \n    plt.savefig(f'Neighborhoods{angle}.png')\n    plt.clf()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:41:49.481467Z","iopub.execute_input":"2023-02-07T19:41:49.482207Z","iopub.status.idle":"2023-02-07T19:44:27.344529Z","shell.execute_reply.started":"2023-02-07T19:41:49.482169Z","shell.execute_reply":"2023-02-07T19:44:27.34348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### build a gif from all the images","metadata":{}},{"cell_type":"code","source":"with imageio.v2.get_writer(f'Neighborhoods.gif', mode='I', duration=0.15) as writer:\n    for angle in angles:\n        file_name = f'Neighborhoods{angle}.png'\n        image = imageio.v2.imread(file_name)\n        writer.append_data(image)\n        \n        # delete the image\n        os.remove(file_name)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:44:27.346384Z","iopub.execute_input":"2023-02-07T19:44:27.347317Z","iopub.status.idle":"2023-02-07T19:45:18.098567Z","shell.execute_reply.started":"2023-02-07T19:44:27.347287Z","shell.execute_reply":"2023-02-07T19:45:18.09745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('Neighborhoods.gif','rb') as f:\n    display(Image(data=f.read(), format='png'))","metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:45:18.103548Z","iopub.execute_input":"2023-02-07T19:45:18.105861Z","iopub.status.idle":"2023-02-07T19:45:18.94773Z","shell.execute_reply.started":"2023-02-07T19:45:18.105823Z","shell.execute_reply":"2023-02-07T19:45:18.944695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The prediction in green is looking good\nIt seems that the selection of the variables for the regression was correct,<br>\nthere are neighborhoods where the area has a greater influence and<br>\nthere are neighborhoods where the year has a greater influence.<br><br>\nYou can see how the prediction in green fits the data well.","metadata":{}},{"cell_type":"markdown","source":"## Next will be ordinal","metadata":{}},{"cell_type":"code","source":"ordinal_cols = {'YrSold', 'GarageCars', 'MoSold', 'KitchenAbvGr', 'BsmtHalfBath', 'BsmtFullBath', 'FullBath', 'HeatingQC', 'BsmtFinType2', 'BsmtExposure', 'BsmtCond', 'BsmtQual', 'ExterCond', 'ExterQual', 'LotShape', 'LandContour', 'LandSlope', 'OverallQual', 'OverallCond'}\n\ndf_ordinal = df[['SalePrice', 'Neighborhood', *ordinal_cols]]","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:02:51.019828Z","iopub.execute_input":"2023-01-14T20:02:51.020182Z","iopub.status.idle":"2023-01-14T20:02:51.026712Z","shell.execute_reply.started":"2023-01-14T20:02:51.020153Z","shell.execute_reply":"2023-01-14T20:02:51.025493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_ordinal_rank_column(df: pd.DataFrame, column_name: str, order: list) -> pd.DataFrame:\n    df[f'{column_name}_rank'] = df.apply(lambda row: order.index(row[column_name]), axis=1)\n    return df.copy()","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:02:52.453182Z","iopub.execute_input":"2023-01-14T20:02:52.453615Z","iopub.status.idle":"2023-01-14T20:02:52.463972Z","shell.execute_reply.started":"2023-01-14T20:02:52.453579Z","shell.execute_reply":"2023-01-14T20:02:52.462886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### understand the values","metadata":{}},{"cell_type":"code","source":"for col in ordinal_cols:\n    print(col, df_ordinal[col].unique(), sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:02:54.924197Z","iopub.execute_input":"2023-01-14T20:02:54.924592Z","iopub.status.idle":"2023-01-14T20:02:54.937533Z","shell.execute_reply.started":"2023-01-14T20:02:54.924559Z","shell.execute_reply":"2023-01-14T20:02:54.935465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fix values into ordinal numbers","metadata":{}},{"cell_type":"code","source":"def get_rank(value, order: list) -> int:\n    try:\n        return order.index(value)\n    except:\n        return -1","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:02:56.229224Z","iopub.execute_input":"2023-01-14T20:02:56.229947Z","iopub.status.idle":"2023-01-14T20:02:56.235411Z","shell.execute_reply.started":"2023-01-14T20:02:56.229908Z","shell.execute_reply":"2023-01-14T20:02:56.234273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ordinal_cols_with_order = [\n    ('HeatingQC', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('BsmtFinType2', ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ']),\n    ('BsmtExposure', ['NA', 'No', 'Mn', 'Av', 'Gd']),\n    ('BsmtCond', ['Po', 'Fa', 'Ta', 'Gd']),\n    ('BsmtQual', ['Fa', 'Ta', 'Gd', 'Ex']),\n    ('ExterCond', ['Po', 'Fa', 'TA', 'Gd', 'Ex']),\n    ('ExterQual', ['Fa', 'Ta', 'Gd', 'Ex']),\n    ('LotShape', ['Reg', 'IR1', 'IR2', 'IR3']),\n    ('LandContour', ['Lvl', 'Bnk', 'HLS', 'Low']),\n    ('LandSlope', ['Gtl', 'Mod', 'Sev'])\n]","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:02:56.751742Z","iopub.execute_input":"2023-01-14T20:02:56.752105Z","iopub.status.idle":"2023-01-14T20:02:56.758997Z","shell.execute_reply.started":"2023-01-14T20:02:56.752076Z","shell.execute_reply":"2023-01-14T20:02:56.758001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col_order in ordinal_cols_with_order:\n    df_ordinal.insert(0, f'{col_order[0]}_rank',df_ordinal.apply(lambda row: get_rank(row[col_order[0]], col_order[1]), axis=1), True)","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:02:56.902486Z","iopub.execute_input":"2023-01-14T20:02:56.903086Z","iopub.status.idle":"2023-01-14T20:02:57.063653Z","shell.execute_reply.started":"2023-01-14T20:02:56.903049Z","shell.execute_reply":"2023-01-14T20:02:57.062685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## first thing- find correlation between columns and get rid of duplicates","metadata":{}},{"cell_type":"code","source":"corr = df_ordinal.corr()\nfig, ax = plt.subplots(figsize = (20, 15))\nsns.heatmap(corr, annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:02:57.709301Z","iopub.execute_input":"2023-01-14T20:02:57.710027Z","iopub.status.idle":"2023-01-14T20:02:59.889152Z","shell.execute_reply.started":"2023-01-14T20:02:57.709989Z","shell.execute_reply":"2023-01-14T20:02:59.88818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The main findings:\n1. OverallQual, ExtraQual_rank -> 0.7\n2. OverallQual, BsmtQual_rank -> 0.64\n3. LandContour_rank, LandSlope_rank -> 0.61\n4. OverallQual, GarageCars -> 0.6\n5. OverallQual, FullBath -> 0.55\n6. **OverallQual, SalePrice -> 0.79**\n\n#### OverallQual seems to have highest correlation with our target ('SalePrice'), but also be in correlation with the other high corr data\n#### Therfore I will stay with it","metadata":{}},{"cell_type":"code","source":"# calculate spearman's correlation\ncorr, _ = spearmanr(df_ordinal.OverallQual, df_ordinal.SalePrice)\nprint('Spearmans correlation: %.3f' % corr)\n\ndf_ordinal.boxplot(column=['SalePrice'], by='OverallQual', grid=False, figsize = (20, 10))","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:02:59.891319Z","iopub.execute_input":"2023-01-14T20:02:59.891999Z","iopub.status.idle":"2023-01-14T20:03:00.25047Z","shell.execute_reply.started":"2023-01-14T20:02:59.89196Z","shell.execute_reply":"2023-01-14T20:03:00.249575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(df['OverallQual'])","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:03:00.251988Z","iopub.execute_input":"2023-01-14T20:03:00.252351Z","iopub.status.idle":"2023-01-14T20:03:00.48232Z","shell.execute_reply.started":"2023-01-14T20:03:00.252315Z","shell.execute_reply":"2023-01-14T20:03:00.481393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The median is: ', df_ordinal.OverallQual.quantile(0.5))\ndf_ordinal.groupby(['OverallQual'])[['OverallQual']].count()","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:03:00.484577Z","iopub.execute_input":"2023-01-14T20:03:00.484986Z","iopub.status.idle":"2023-01-14T20:03:00.502477Z","shell.execute_reply.started":"2023-01-14T20:03:00.48495Z","shell.execute_reply":"2023-01-14T20:03:00.500495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## So what to do with OverallQual?\nEarlier I cleared outliers of area and year compared to the price.<br>\nBut what makes a value outlier?<br>\nThis can be due to reasons that are not suitable for learning, for example:<br>\n* A very competent real estate agent can increase the selling price.\n* An apartment in front of a noisy party club that can reduce the value of the apartment.\n* Etc...","metadata":{}},{"cell_type":"markdown","source":"### But OverallQual is given!\n\nThe median of OverallQual is 6.<br>\n**My hypothesis:**<br>\n*The higher the score, the more renovated and preserved the house is, which is the opposite of an old house (conceptually).*\n<br>","metadata":{}},{"cell_type":"code","source":"# this dict keys will be the neighborhoods names and the values will be the corresponding models\narea_year_regressors_with_OverallQual = {}\n\n# Note: now we will use the whole DataFrame with \"outlairs\" to\n# test if we can understand them with OverallQual\nfor nei in df.Neighborhood.unique():\n    # only rows of this Neighborhood\n    df_temp = df[df.Neighborhood == nei]\n    X_train, y_train = df_temp[['GrLivArea', 'YearBuilt', 'OverallQual']].to_numpy(), df_temp.SalePrice.to_numpy()\n    \n    poly = PolynomialFeatures(2)\n    regressor = Ridge(alpha=1000)\n    \n    X_train_trans = poly.fit_transform(X_train)\n    regressor.fit(X_train_trans, y_train)\n    \n    # add the new calculated regressor to the regressors dict\n    area_year_regressors_with_OverallQual[nei] = regressor","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:10:32.337238Z","iopub.execute_input":"2023-01-14T20:10:32.337627Z","iopub.status.idle":"2023-01-14T20:10:32.398016Z","shell.execute_reply.started":"2023-01-14T20:10:32.337592Z","shell.execute_reply":"2023-01-14T20:10:32.397032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_improvment = 0\ndata = []\n\nfor nei in df_continuous.Neighborhood.unique():\n    # only rows of this Neighborhood\n    df_temp = df[df.Neighborhood == nei]\n    \n    X = df_temp[['GrLivArea', 'YearBuilt']].to_numpy()\n    X_trans = poly.fit_transform(X)\n    y = df_temp.SalePrice.to_numpy()\n    \n    regressor = area_year_regressors[nei]\n    \n    y_predict = regressor.predict(X_trans)\n    COUNT_OF_HOUSES= len(y)\n#     print(f'{nei} with {COUNT_OF_HOUSES} houses')\n    \n    # numpy array of each absolute error\n    errors = np.absolute(y - y_predict)\n    avg_error = errors.sum()/COUNT_OF_HOUSES\n    \n#     print('avg_error with YearBuilt: ',avg_error)\n    \n    regressor = area_year_regressors_with_OverallQual[nei]\n    \n    X = df_temp[['GrLivArea', 'YearBuilt', 'OverallQual']].to_numpy()\n    X_trans = poly.fit_transform(X)\n    y_predict = regressor.predict(X_trans)\n    \n    # numpy array of each absolute error\n    errors = np.absolute(y - y_predict)\n    avg_error2 = errors.sum()/COUNT_OF_HOUSES\n    delta = avg_error - avg_error2\n#     print('avg_error2 with year_OverallQual: ',avg_error2)\n#     print(f'total decrease: {delta} which is {delta/avg_error}%', end='\\n\\n')\n    total_improvment += delta * COUNT_OF_HOUSES\n    \n    corr, _ = spearmanr(df_temp.OverallQual, df_temp.SalePrice)\n    data.append(\n        {\n            'Neighborhood': nei,\n            'COUNT_OF_HOUSES': COUNT_OF_HOUSES,\n            'avg_error': avg_error,\n            'avg_error_OverallQual': avg_error2,\n            'delta': delta,\n            'percent': delta/avg_error,\n            'corr': corr\n        }\n    )\n\nprint(f'In total the improvment was: {total_improvment}')","metadata":{"execution":{"iopub.status.busy":"2023-01-14T20:10:41.997958Z","iopub.execute_input":"2023-01-14T20:10:41.998325Z","iopub.status.idle":"2023-01-14T20:10:42.030841Z","shell.execute_reply.started":"2023-01-14T20:10:41.99829Z","shell.execute_reply":"2023-01-14T20:10:42.02936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_df = pd.json_normalize(data).sort_values(by='percent')\nscore_df","metadata":{"execution":{"iopub.status.busy":"2023-01-08T22:42:26.582579Z","iopub.execute_input":"2023-01-08T22:42:26.583093Z","iopub.status.idle":"2023-01-08T22:42:26.615001Z","shell.execute_reply.started":"2023-01-08T22:42:26.58305Z","shell.execute_reply":"2023-01-08T22:42:26.613541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As you can see, the general prediction improved\nAlthough some of the forecasts for the neighborhoods got worse.","metadata":{}},{"cell_type":"markdown","source":"## Categorical (The work on the categorical part is not yet finished)","metadata":{}},{"cell_type":"code","source":"categorical_cols = {'GarageType', 'Electrical', 'Heating', 'Foundation', 'CentralAir', 'MasVnrType', 'Exterior2nd', 'Exterior1st', 'RoofMatl', 'RoofStyle', 'MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotConfig', 'Condition1', 'Utilities', 'Condition2', 'BldgType', 'HouseStyle'}\ndf_cat = df[['SalePrice', 'Neighborhood', *categorical_cols]]","metadata":{"execution":{"iopub.status.busy":"2023-01-14T19:34:49.188672Z","iopub.execute_input":"2023-01-14T19:34:49.189036Z","iopub.status.idle":"2023-01-14T19:34:49.196127Z","shell.execute_reply.started":"2023-01-14T19:34:49.189004Z","shell.execute_reply":"2023-01-14T19:34:49.195174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for cat in categorical_cols:\n    df_cat.boxplot(column=['SalePrice'], by=cat, grid=False, figsize = (20, 10))","metadata":{"execution":{"iopub.status.busy":"2023-01-14T19:35:02.965502Z","iopub.execute_input":"2023-01-14T19:35:02.966502Z","iopub.status.idle":"2023-01-14T19:35:08.856328Z","shell.execute_reply.started":"2023-01-14T19:35:02.966429Z","shell.execute_reply":"2023-01-14T19:35:08.8554Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# {'Heating', 'Foundation', 'CentralAir', 'Exterior2nd', 'Exterior1st', 'RoofMatl', 'RoofStyle', 'MSSubClass', 'MSZoning', 'Alley', 'Condition1', 'Condition2'}","metadata":{"execution":{"iopub.status.busy":"2023-01-14T19:49:47.730112Z","iopub.execute_input":"2023-01-14T19:49:47.730502Z","iopub.status.idle":"2023-01-14T19:49:47.736104Z","shell.execute_reply.started":"2023-01-14T19:49:47.730463Z","shell.execute_reply":"2023-01-14T19:49:47.735048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_cat.groupby('MSZoning')[['MSZoning', 'SalePrice']].median().sort_values(by='SalePrice')","metadata":{"execution":{"iopub.status.busy":"2023-01-08T20:32:29.068208Z","iopub.status.idle":"2023-01-08T20:32:29.069041Z","shell.execute_reply.started":"2023-01-08T20:32:29.068781Z","shell.execute_reply":"2023-01-08T20:32:29.068803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GROUPS_NUM = 5\n# sub_size = int(df_cat.shape[0]/GROUPS_NUM)-1\n# sub_size","metadata":{"execution":{"iopub.status.busy":"2023-01-08T20:32:29.070625Z","iopub.status.idle":"2023-01-08T20:32:29.071041Z","shell.execute_reply.started":"2023-01-08T20:32:29.070801Z","shell.execute_reply":"2023-01-08T20:32:29.070817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# groups_list = [i for i in range(GROUPS_NUM) for _ in range(sub_size)]\n# groups_list.extend((df_cat.shape[0] -len(groups_list)) * [GROUPS_NUM])\n\n# df_cat.sort_values(by='SalePrice', inplace=True)\n# df_cat.insert(0, 'price_group', groups_list, True)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T20:32:29.072193Z","iopub.status.idle":"2023-01-08T20:32:29.072552Z","shell.execute_reply.started":"2023-01-08T20:32:29.072375Z","shell.execute_reply":"2023-01-08T20:32:29.072391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df.insert(0, 'price_group', df_cat.price_group, True)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T20:32:29.073524Z","iopub.status.idle":"2023-01-08T20:32:29.073973Z","shell.execute_reply.started":"2023-01-08T20:32:29.073714Z","shell.execute_reply":"2023-01-08T20:32:29.073731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_cat = df[:df.shape[0] - sub_size]\n# test_cat = df[df.shape[0] - sub_size:]","metadata":{"execution":{"iopub.status.busy":"2023-01-08T20:32:29.075068Z","iopub.status.idle":"2023-01-08T20:32:29.075591Z","shell.execute_reply.started":"2023-01-08T20:32:29.075329Z","shell.execute_reply":"2023-01-08T20:32:29.075356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gnb = GaussianNB()\n# X_train, y_train = train_cat['CentralAir'], train_cat.price_group\n# X_test, y_test = test_cat['CentralAir'], test_cat.price_group\n\n# # accuracies = cross_val_score(gnb, X_train, y_train, cv=5)\n# gnb.fit(X_train, y_train)\n# y_pred = gnb.predict(X_test)\n ","metadata":{"execution":{"iopub.status.busy":"2023-01-08T20:32:29.077766Z","iopub.status.idle":"2023-01-08T20:32:29.078151Z","shell.execute_reply.started":"2023-01-08T20:32:29.077967Z","shell.execute_reply":"2023-01-08T20:32:29.077984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_category_pred(df: pd.DataFrame, category_col: str) -> pd.DataFrame:\n#     t = df.groupby(by=[category_col, 'price_group'])[\"price_group\"].count().reset_index(name=\"count\")\n#     s = t.groupby(by=category_col)['count'].idxmax()\n#     return t.loc[s]","metadata":{"execution":{"iopub.status.busy":"2023-01-08T20:32:29.080334Z","iopub.status.idle":"2023-01-08T20:32:29.08071Z","shell.execute_reply.started":"2023-01-08T20:32:29.080529Z","shell.execute_reply":"2023-01-08T20:32:29.080546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # cat_cols = {'Condition1', 'Condition2', }\n# for col in categorical_cols:\n#     temp = get_category_pred(df_cat, col)\n#     df_cat = df_cat.join(other=temp)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T20:32:29.08162Z","iopub.status.idle":"2023-01-08T20:32:29.082033Z","shell.execute_reply.started":"2023-01-08T20:32:29.081799Z","shell.execute_reply":"2023-01-08T20:32:29.081816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"id_list = []\nprice_list = []\n\nfor nei in df_test.Neighborhood.unique():\n    # only rows of this Neighborhood\n    df_temp = df_test[df_test.Neighborhood == nei]\n    regressor = area_year_regressors_with_OverallQual[nei]\n    \n    X = df_temp[['GrLivArea', 'YearBuilt', 'OverallQual']].to_numpy()\n    X_trans = poly.fit_transform(X)\n    y_predict = regressor.predict(X_trans)\n    \n    id_list.extend(df_temp.Id.to_list())\n    price_list.extend(y_predict.tolist())","metadata":{"execution":{"iopub.status.busy":"2023-01-08T22:44:21.600985Z","iopub.execute_input":"2023-01-08T22:44:21.601519Z","iopub.status.idle":"2023-01-08T22:44:21.661812Z","shell.execute_reply.started":"2023-01-08T22:44:21.601468Z","shell.execute_reply":"2023-01-08T22:44:21.660736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = {'Id': id_list, 'SalePrice': price_list}\n\ndf_submission = pd.DataFrame(data=data)\ndf_submission","metadata":{"execution":{"iopub.status.busy":"2023-01-08T22:44:22.123494Z","iopub.execute_input":"2023-01-08T22:44:22.124988Z","iopub.status.idle":"2023-01-08T22:44:22.142092Z","shell.execute_reply.started":"2023-01-08T22:44:22.1249Z","shell.execute_reply":"2023-01-08T22:44:22.140845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T20:32:29.090529Z","iopub.status.idle":"2023-01-08T20:32:29.090868Z","shell.execute_reply.started":"2023-01-08T20:32:29.0907Z","shell.execute_reply":"2023-01-08T20:32:29.090716Z"},"trusted":true},"execution_count":null,"outputs":[]}]}